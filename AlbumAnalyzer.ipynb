{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Album Analyzer\n",
    "\n",
    "\n",
    "This notebook will take the artist name and album name of a given artist and album and will query the user to confirm the album they want to select. \n",
    "\n",
    "\n",
    "The notebook will then grab all the lyrics from the album and perform sentiment analysis on it, then it will graph the sentiment analysis and create a word cloud. I am planning on adding a few more features, but for what it is right now, this is what it'll do.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lyricsgenius\n",
    "!pip install vaderSentiment\n",
    "!pip install nltk\n",
    "import nltk\n",
    "import json\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from lyricsgenius import Genius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ask the user to input an artist and an album\n",
    "artist = input(\"Enter an artist: \")\n",
    "album = input(\"Enter an album: \")\n",
    "\n",
    "#set up genius api\n",
    "genius = Genius('PUT YOUR GENIUS API KEY HERE')\n",
    "\n",
    "#search for the album\n",
    "album = genius.search_albums(str(artist) + \" \" + str(album))\n",
    "\n",
    "album_names = []\n",
    "album_ids = []\n",
    "for i in range(len(album['sections'][0]['hits'])):\n",
    "    album_names.append(album['sections'][0]['hits'][i]['result']['name'])\n",
    "    album_ids.append(album['sections'][0]['hits'][i]['result']['id'])\n",
    "album_df = pd.DataFrame({'album_name': album_names, 'album_id': album_ids})\n",
    "album_df['choice'] = album_df.index\n",
    "album_df['choice'] = album_df['choice'] + 1\n",
    "\n",
    "album_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_album(choice):\n",
    "    album_name = album_df.loc[album_df['choice'] == choice, 'album_name'].iloc[0]\n",
    "    album_id = album_df.loc[album_df['choice'] == choice, 'album_id'].iloc[0]\n",
    "    return album_name, album_id\n",
    "\n",
    "#ask the user to input a choice\n",
    "choice = int(input(\"Enter a choice: \"))\n",
    "#call the get_album function\n",
    "album_name, album_id = get_album(choice)\n",
    "#display the album name and id``\n",
    "print(album_name)\n",
    "print(album_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "album = genius.search_album(str(artist) + \" \" + str(album), album_id=album_id)\n",
    "album.save_lyrics('lyrics.json', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the lyrics\n",
    "with open('lyrics.json') as f:\n",
    "    data = json.load(f)\n",
    "    print(json.dumps(data, indent=4, sort_keys=True))\n",
    "    print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the json file and print in a readable format and print keys\n",
    "import json\n",
    "with open('lyrics.json') as f:\n",
    "    data = json.load(f)\n",
    "    print(json.dumps(data, indent=4, sort_keys=True))\n",
    "    print(data.keys())\n",
    "\n",
    "#count the number of ids in the json file\n",
    "print(len(data['tracks']))\n",
    "\n",
    "#print the keys under 'tracks' in the json file\n",
    "print(data['tracks'][0].keys())\n",
    "\n",
    "#print the keys under 'song' in the json file\n",
    "print(data['tracks'][0]['song'].keys())\n",
    "\n",
    "#print the lyrics under each song in the json file\n",
    "for i in range(len(data['tracks'])):\n",
    "    print(data['tracks'][i]['song']['lyrics'])\n",
    "    \n",
    "\n",
    "#add each song and its lyrics to a dataframe\n",
    "df = pd.DataFrame(columns=['song', 'lyrics'])\n",
    "for i in range(len(data['tracks'])):\n",
    "    df = df.append({'song': data['tracks'][i]['song']['title'], 'lyrics': data['tracks'][i]['song']['lyrics']}, ignore_index=True)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each lyric is a string that starts with the song title, remove the song title\n",
    "df['lyrics'] = df['lyrics'].str.replace(r'^.*\\n', '')\n",
    "df\n",
    "\n",
    "#remove all punctuation, convert to lowercase, and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df['lyrics'] = df['lyrics'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word.lower()) for word in tokenizer.tokenize(x) if word not in stop_words]))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each song, calculate the sentiment score and add it to a new column\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "df['sentiment_score'] = df['lyrics'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "df\n",
    "\n",
    "#perform sentiment analysis on the lyrics of each song, and add the result to a new column, sentiment\n",
    "df['sentiment'] = df['sentiment_score'].apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutral')\n",
    "df\n",
    "\n",
    "#tokenize the lyrics of each song, split the lyrics into a list of words and add it to a new column\n",
    "df['tokenized_lyrics'] = df['lyrics'].apply(lambda x: word_tokenize(x))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph the sentiment analysis of each song\n",
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Sentiment Analysis of ' + str(album_name))\n",
    "sns.barplot(x='song', y='sentiment_score', data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#graph the sentiment analysis of the album including the average sentiment score\n",
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x='sentiment', data=df)\n",
    "plt.title('Sentiment Analysis of ' + str(album_name))\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "print('Average Sentiment Score: ' + str(df['sentiment_score'].mean()))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a word cloud of the lyrics of the album\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Word Cloud of ' + str(album_name))\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=100).generate(' '.join(df['lyrics']))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d1e37ab42fdcd25737c9d7ec581bdd15084cf0e3ae43de527cc420fc4ac3388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
